{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Interactivo: API REST para Migración de CSV a Base de Datos SQL\n",
    "\n",
    "Este notebook te permite explorar y ejecutar paso a paso cada componente del proyecto de API REST para migración de datos CSV a una base de datos SQL.\n",
    "\n",
    "## Estructura del Proyecto\n",
    "\n",
    "```\n",
    "csv_api_migration/\n",
    "│\n",
    "├── app/\n",
    "│   ├── database/\n",
    "│   │   ├── create_db.py       # Script para crear la base de datos\n",
    "│   │   ├── db_manager.py      # Gestor de operaciones de base de datos\n",
    "│   │   └── migration.db       # Archivo de base de datos SQLite (generado automáticamente)\n",
    "│   │\n",
    "│   ├── routes/                # Directorio para rutas adicionales (extensible)\n",
    "│   │\n",
    "│   ├── utils/\n",
    "│   │   └── csv_processor.py   # Utilidades para procesar archivos CSV\n",
    "│   │\n",
    "│   └── main.py               # Punto de entrada principal de la API\n",
    "│\n",
    "├── data/                     # Directorio para archivos CSV\n",
    "│\n",
    "├── tests/                    # Directorio para pruebas unitarias\n",
    "│\n",
    "├── test_api.py               # Script para probar la API\n",
    "│\n",
    "├── requirements.txt          # Dependencias del proyecto\n",
    "│\n",
    "└── README.md                 # Documentación del proyecto\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: Configuración del Entorno\n",
    "\n",
    "Primero, instalamos las dependencias necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.95.1)\n",
      "Requirement already satisfied: uvicorn in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.22.0)\n",
      "Requirement already satisfied: python-multipart in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.6)\n",
      "Requirement already satisfied: requests in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from fastapi) (1.10.22)\n",
      "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from fastapi) (0.26.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from uvicorn) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from starlette<0.27.0,>=0.26.1->fastapi) (4.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi) (1.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\VladimirPerez\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install fastapi uvicorn python-multipart requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (2.2.3)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\VladimirPerez\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-multipart==0.0.6 in c:\\users\\vladimirperez\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.0.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\VladimirPerez\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install python-multipart==0.0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chromadb 0.6.3 has requirement fastapi>=0.95.2, but you have fastapi 0.95.1.\n",
      "langchain 0.3.19 has requirement pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.22.\n",
      "langchain-community 0.0.38 has requirement langchain-core<0.2.0,>=0.1.52, but you have langchain-core 0.3.35.\n",
      "langchain-core 0.3.35 has requirement pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.22.\n"
     ]
    }
   ],
   "source": [
    "!pip check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Análisis de los Archivos CSV\n",
    "\n",
    "Vamos a examinar la estructura de los archivos CSV para entender los datos que vamos a migrar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos en el directorio de datos: ['departments.csv', 'hired_employees.csv', 'jobs.csv']\n",
      "\n",
      "Departments:\n",
      "   id                department\n",
      "0   1        Product Management\n",
      "1   2                     Sales\n",
      "2   3  Research and Development\n",
      "3   4      Business Development\n",
      "4   5               Engineering\n",
      "\n",
      "Jobs:\n",
      "   id                        job\n",
      "0   1        Marketing Assistant\n",
      "1   2                   VP Sales\n",
      "2   3         Biostatistician IV\n",
      "3   4  Account Representative II\n",
      "4   5               VP Marketing\n",
      "\n",
      "Hired Employees:\n",
      "   id            name              datetime  department_id  job_id\n",
      "0   1     Harold Vogt  2021-11-07T02:48:42Z            2.0    96.0\n",
      "1   2        Ty Hofer  2021-05-30T05:43:46Z            8.0     NaN\n",
      "2   3     Lyman Hadye  2021-09-01T23:27:38Z            5.0    52.0\n",
      "3   4   Lotti Crowthe  2021-10-01T13:04:21Z           12.0    71.0\n",
      "4   5  Gretna Lording  2021-10-10T22:22:17Z            6.0    80.0\n",
      "\n",
      "Información sobre Departments:\n",
      "Número de registros: 12\n",
      "id             int64\n",
      "department    object\n",
      "dtype: object\n",
      "\n",
      "Información sobre Jobs:\n",
      "Número de registros: 183\n",
      "id      int64\n",
      "job    object\n",
      "dtype: object\n",
      "\n",
      "Información sobre Hired Employees:\n",
      "Número de registros: 1999\n",
      "id                 int64\n",
      "name              object\n",
      "datetime          object\n",
      "department_id    float64\n",
      "job_id           float64\n",
      "dtype: object\n",
      "Valores nulos en department_id: 21\n",
      "Valores nulos en job_id: 16\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Definir la ruta a los archivos CSV\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "# Verificar si los archivos existen\n",
    "print(f\"Archivos en el directorio de datos: {os.listdir(data_dir)}\")\n",
    "\n",
    "# Leer los archivos CSV\n",
    "departments_df = pd.read_csv(os.path.join(data_dir, 'departments.csv'), header=None, names=['id', 'department'])\n",
    "jobs_df = pd.read_csv(os.path.join(data_dir, 'jobs.csv'), header=None, names=['id', 'job'])\n",
    "employees_df = pd.read_csv(os.path.join(data_dir, 'hired_employees.csv'), header=None, \n",
    "                          names=['id', 'name', 'datetime', 'department_id', 'job_id'])\n",
    "\n",
    "# Mostrar las primeras filas de cada DataFrame\n",
    "print(\"\\nDepartments:\")\n",
    "print(departments_df.head())\n",
    "\n",
    "print(\"\\nJobs:\")\n",
    "print(jobs_df.head())\n",
    "\n",
    "print(\"\\nHired Employees:\")\n",
    "print(employees_df.head())\n",
    "\n",
    "# Mostrar información sobre los DataFrames\n",
    "print(\"\\nInformación sobre Departments:\")\n",
    "print(f\"Número de registros: {len(departments_df)}\")\n",
    "print(departments_df.dtypes)\n",
    "\n",
    "print(\"\\nInformación sobre Jobs:\")\n",
    "print(f\"Número de registros: {len(jobs_df)}\")\n",
    "print(jobs_df.dtypes)\n",
    "\n",
    "print(\"\\nInformación sobre Hired Employees:\")\n",
    "print(f\"Número de registros: {len(employees_df)}\")\n",
    "print(employees_df.dtypes)\n",
    "print(f\"Valores nulos en department_id: {employees_df['department_id'].isna().sum()}\")\n",
    "print(f\"Valores nulos en job_id: {employees_df['job_id'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3: Creación de la Base de Datos\n",
    "\n",
    "Ahora vamos a examinar y ejecutar el script para crear la base de datos SQLite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero, veamos el contenido del script create_db.py\n",
    "with open('app/database/create_db.py', 'r') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora, importamos y ejecutamos la función para crear la base de datos\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from app.database.create_db import create_database\n",
    "\n",
    "db_path = create_database()\n",
    "print(f\"Base de datos creada en: {db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4: Gestor de Base de Datos\n",
    "\n",
    "Examinemos el gestor de base de datos que se encarga de las operaciones con SQLite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "MÃ³dulo para manejar las operaciones de base de datos\n",
      "\"\"\"\n",
      "import sqlite3\n",
      "import os\n",
      "from typing import List, Dict, Any, Tuple\n",
      "\n",
      "class DatabaseManager:\n",
      "    def __init__(self, db_path=None):\n",
      "        \"\"\"\n",
      "        Inicializa el gestor de base de datos.\n",
      "        \n",
      "        Args:\n",
      "            db_path: Ruta al archivo de base de datos SQLite. Si es None, \n",
      "                    se usa la ruta predeterminada.\n",
      "        \"\"\"\n",
      "        if db_path is None:\n",
      "            db_dir = os.path.dirname(os.path.abspath(__file__))\n",
      "            self.db_path = os.path.join(db_dir, 'migration.db')\n",
      "        else:\n",
      "            self.db_path = db_path\n",
      "    \n",
      "    def get_connection(self) -> Tuple[sqlite3.Connection, sqlite3.Cursor]:\n",
      "        \"\"\"\n",
      "        Obtiene una conexiÃ³n a la base de datos.\n",
      "        \n",
      "        Returns:\n",
      "            Tupla con la conexiÃ³n y el cursor.\n",
      "        \"\"\"\n",
      "        conn = sqlite3.connect(self.db_path)\n",
      "        cursor = conn.cursor()\n",
      "        return conn, cursor\n",
      "    \n",
      "    def close_connection(self, conn: sqlite3.Connection):\n",
      "        \"\"\"\n",
      "        Cierra una conexiÃ³n a la base de datos.\n",
      "        \n",
      "        Args:\n",
      "            conn: ConexiÃ³n a cerrar.\n",
      "        \"\"\"\n",
      "        if conn:\n",
      "            conn.close()\n",
      "    \n",
      "    def insert_batch(self, table_name: str, data: List[Dict[str, Any]]) -> int:\n",
      "        \"\"\"\n",
      "        Inserta un lote de registros en la tabla especificada.\n",
      "        \n",
      "        Args:\n",
      "            table_name: Nombre de la tabla donde insertar los datos.\n",
      "            data: Lista de diccionarios con los datos a insertar.\n",
      "            \n",
      "        Returns:\n",
      "            NÃºmero de registros insertados.\n",
      "        \"\"\"\n",
      "        if not data:\n",
      "            return 0\n",
      "        \n",
      "        # Obtener las columnas del primer registro\n",
      "        columns = list(data[0].keys())\n",
      "        placeholders = ', '.join(['?' for _ in columns])\n",
      "        columns_str = ', '.join(columns)\n",
      "        \n",
      "        # Preparar la consulta SQL\n",
      "        query = f\"INSERT INTO {table_name} ({columns_str}) VALUES ({placeholders})\"\n",
      "        \n",
      "        # Preparar los valores para la inserciÃ³n\n",
      "        values = []\n",
      "        for record in data:\n",
      "            row_values = [record.get(column) for column in columns]\n",
      "            values.append(tuple(row_values))\n",
      "        \n",
      "        # Ejecutar la inserciÃ³n por lotes\n",
      "        conn, cursor = self.get_connection()\n",
      "        try:\n",
      "            cursor.executemany(query, values)\n",
      "            conn.commit()\n",
      "            return cursor.rowcount\n",
      "        except sqlite3.Error as e:\n",
      "            conn.rollback()\n",
      "            raise e\n",
      "        finally:\n",
      "            self.close_connection(conn)\n",
      "    \n",
      "    def execute_query(self, query: str, params=None):\n",
      "        \"\"\"\n",
      "        Ejecuta una consulta SQL.\n",
      "        \n",
      "        Args:\n",
      "            query: Consulta SQL a ejecutar.\n",
      "            params: ParÃ¡metros para la consulta (opcional).\n",
      "            \n",
      "        Returns:\n",
      "            Resultado de la consulta.\n",
      "        \"\"\"\n",
      "        conn, cursor = self.get_connection()\n",
      "        try:\n",
      "            if params:\n",
      "                cursor.execute(query, params)\n",
      "            else:\n",
      "                cursor.execute(query)\n",
      "            \n",
      "            result = cursor.fetchall()\n",
      "            conn.commit()\n",
      "            return result\n",
      "        except sqlite3.Error as e:\n",
      "            conn.rollback()\n",
      "            raise e\n",
      "        finally:\n",
      "            self.close_connection(conn)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ver el contenido del script db_manager.py\n",
    "with open('app/database/db_manager.py', 'r') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros insertados: 1\n",
      "Resultado de la consulta: [(100, 'Test Department')]\n"
     ]
    }
   ],
   "source": [
    "# Probar el gestor de base de datos con una inserción simple\n",
    "from app.database.db_manager import DatabaseManager\n",
    "\n",
    "# Crear una instancia del gestor de base de datos\n",
    "db_manager = DatabaseManager()\n",
    "\n",
    "# Insertar un departamento de prueba\n",
    "test_department = [{\"id\": 100, \"department\": \"Test Department\"}]\n",
    "inserted_count = db_manager.insert_batch(\"departments\", test_department)\n",
    "print(f\"Registros insertados: {inserted_count}\")\n",
    "\n",
    "# Verificar la inserción\n",
    "result = db_manager.execute_query(\"SELECT * FROM departments WHERE id = 100\")\n",
    "print(f\"Resultado de la consulta: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5: Procesador de CSV\n",
    "\n",
    "Veamos cómo funciona el procesador de archivos CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "Utilidades para procesar archivos CSV\n",
      "\"\"\"\n",
      "import csv\n",
      "import os\n",
      "from typing import List, Dict, Any\n",
      "\n",
      "def parse_csv_file(file_path: str) -> List[Dict[str, Any]]:\n",
      "    \"\"\"\n",
      "    Lee un archivo CSV y lo convierte en una lista de diccionarios.\n",
      "    \n",
      "    Args:\n",
      "        file_path: Ruta al archivo CSV.\n",
      "        \n",
      "    Returns:\n",
      "        Lista de diccionarios con los datos del CSV.\n",
      "    \"\"\"\n",
      "    if not os.path.exists(file_path):\n",
      "        raise FileNotFoundError(f\"El archivo {file_path} no existe\")\n",
      "    \n",
      "    data = []\n",
      "    \n",
      "    # Detectar el tipo de archivo por su nombre\n",
      "    file_name = os.path.basename(file_path).lower()\n",
      "    \n",
      "    if 'department' in file_name:\n",
      "        # Estructura para departments.csv: id, department\n",
      "        with open(file_path, 'r', encoding='utf-8') as file:\n",
      "            csv_reader = csv.reader(file)\n",
      "            for row in csv_reader:\n",
      "                if len(row) >= 2:\n",
      "                    data.append({\n",
      "                        'id': int(row[0]),\n",
      "                        'department': row[1]\n",
      "                    })\n",
      "    \n",
      "    elif 'job' in file_name:\n",
      "        # Estructura para jobs.csv: id, job\n",
      "        with open(file_path, 'r', encoding='utf-8') as file:\n",
      "            csv_reader = csv.reader(file)\n",
      "            for row in csv_reader:\n",
      "                if len(row) >= 2:\n",
      "                    data.append({\n",
      "                        'id': int(row[0]),\n",
      "                        'job': row[1]\n",
      "                    })\n",
      "    \n",
      "    elif 'employee' in file_name or 'hired' in file_name:\n",
      "        # Estructura para hired_employees.csv: id, name, datetime, department_id, job_id\n",
      "        with open(file_path, 'r', encoding='utf-8') as file:\n",
      "            csv_reader = csv.reader(file)\n",
      "            for row in csv_reader:\n",
      "                if len(row) >= 5:\n",
      "                    # Manejar posibles valores nulos en department_id y job_id\n",
      "                    department_id = int(row[3]) if row[3].strip() else None\n",
      "                    job_id = int(row[4]) if row[4].strip() else None\n",
      "                    \n",
      "                    data.append({\n",
      "                        'id': int(row[0]),\n",
      "                        'name': row[1],\n",
      "                        'datetime': row[2],\n",
      "                        'department_id': department_id,\n",
      "                        'job_id': job_id\n",
      "                    })\n",
      "    \n",
      "    else:\n",
      "        # Formato genÃ©rico para otros archivos CSV\n",
      "        with open(file_path, 'r', encoding='utf-8') as file:\n",
      "            csv_reader = csv.reader(file)\n",
      "            headers = next(csv_reader, None)\n",
      "            \n",
      "            if headers:\n",
      "                for row in csv_reader:\n",
      "                    if len(row) == len(headers):\n",
      "                        record = {}\n",
      "                        for i, header in enumerate(headers):\n",
      "                            record[header] = row[i]\n",
      "                        data.append(record)\n",
      "    \n",
      "    return data\n",
      "\n",
      "def validate_batch_size(data: List[Dict[str, Any]]) -> bool:\n",
      "    \"\"\"\n",
      "    Valida que el tamaÃ±o del lote estÃ© dentro del rango permitido (1-1000).\n",
      "    \n",
      "    Args:\n",
      "        data: Lista de diccionarios con los datos a validar.\n",
      "        \n",
      "    Returns:\n",
      "        True si el tamaÃ±o es vÃ¡lido, False en caso contrario.\n",
      "    \"\"\"\n",
      "    return 1 <= len(data) <= 1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ver el contenido del script csv_processor.py\n",
    "with open('app/utils/csv_processor.py', 'r') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros procesados: 12\n",
      "Primeros 5 registros:\n",
      "  1. {'id': 1, 'department': 'Product Management'}\n",
      "  2. {'id': 2, 'department': 'Sales'}\n",
      "  3. {'id': 3, 'department': 'Research and Development'}\n",
      "  4. {'id': 4, 'department': 'Business Development'}\n",
      "  5. {'id': 5, 'department': 'Engineering'}\n",
      "¿El tamaño del lote es válido? True\n"
     ]
    }
   ],
   "source": [
    "# Probar el procesador de CSV con uno de los archivos\n",
    "from app.utils.csv_processor import parse_csv_file, validate_batch_size\n",
    "\n",
    "# Procesar el archivo departments.csv\n",
    "departments_data = parse_csv_file(os.path.join(data_dir, 'departments.csv'))\n",
    "print(f\"Número de registros procesados: {len(departments_data)}\")\n",
    "print(\"Primeros 5 registros:\")\n",
    "for i, record in enumerate(departments_data[:5]):\n",
    "    print(f\"  {i+1}. {record}\")\n",
    "\n",
    "# Validar el tamaño del lote\n",
    "is_valid = validate_batch_size(departments_data)\n",
    "print(f\"¿El tamaño del lote es válido? {is_valid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 6: API REST Principal\n",
    "\n",
    "Examinemos el archivo principal de la API REST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "ConfiguraciÃ³n principal de la API REST\n",
      "\"\"\"\n",
      "from fastapi import FastAPI, UploadFile, File, HTTPException, Body\n",
      "from fastapi.responses import JSONResponse\n",
      "from fastapi.middleware.cors import CORSMiddleware\n",
      "import os\n",
      "import tempfile\n",
      "import shutil\n",
      "from typing import List, Dict, Any\n",
      "\n",
      "# Importar mÃ³dulos propios\n",
      "from app.database.create_db import create_database\n",
      "from app.database.db_manager import DatabaseManager\n",
      "from app.utils.csv_processor import parse_csv_file, validate_batch_size\n",
      "\n",
      "# Crear la aplicaciÃ³n FastAPI\n",
      "app = FastAPI(\n",
      "    title=\"API de MigraciÃ³n CSV\",\n",
      "    description=\"API REST para migrar datos desde archivos CSV a una base de datos SQL\",\n",
      "    version=\"1.0.0\"\n",
      ")\n",
      "\n",
      "# Configurar CORS\n",
      "app.add_middleware(\n",
      "    CORSMiddleware,\n",
      "    allow_origins=[\"*\"],\n",
      "    allow_credentials=True,\n",
      "    allow_methods=[\"*\"],\n",
      "    allow_headers=[\"*\"],\n",
      ")\n",
      "\n",
      "# Inicializar la base de datos al iniciar la aplicaciÃ³n\n",
      "@app.on_event(\"startup\")\n",
      "async def startup_event():\n",
      "    db_path = create_database()\n",
      "    print(f\"Base de datos inicializada en: {db_path}\")\n",
      "\n",
      "# Endpoint para verificar el estado de la API\n",
      "@app.get(\"/\")\n",
      "async def root():\n",
      "    return {\"message\": \"API de MigraciÃ³n CSV activa\", \"status\": \"OK\"}\n",
      "\n",
      "# Endpoint para cargar un archivo CSV\n",
      "@app.post(\"/upload/{table_name}\")\n",
      "async def upload_csv(table_name: str, file: UploadFile = File(...)):\n",
      "    \"\"\"\n",
      "    Carga un archivo CSV en la tabla especificada.\n",
      "    \n",
      "    Args:\n",
      "        table_name: Nombre de la tabla donde cargar los datos (departments, jobs, hired_employees).\n",
      "        file: Archivo CSV a cargar.\n",
      "        \n",
      "    Returns:\n",
      "        Mensaje de Ã©xito y nÃºmero de registros insertados.\n",
      "    \"\"\"\n",
      "    # Validar el nombre de la tabla\n",
      "    valid_tables = [\"departments\", \"jobs\", \"hired_employees\"]\n",
      "    if table_name not in valid_tables:\n",
      "        raise HTTPException(\n",
      "            status_code=400, \n",
      "            detail=f\"Tabla no vÃ¡lida. Debe ser una de: {', '.join(valid_tables)}\"\n",
      "        )\n",
      "    \n",
      "    # Guardar el archivo temporalmente\n",
      "    temp_file = tempfile.NamedTemporaryFile(delete=False)\n",
      "    try:\n",
      "        shutil.copyfileobj(file.file, temp_file)\n",
      "        temp_file.close()\n",
      "        \n",
      "        # Procesar el archivo CSV\n",
      "        data = parse_csv_file(temp_file.name)\n",
      "        \n",
      "        # Validar el tamaÃ±o del lote\n",
      "        if not validate_batch_size(data):\n",
      "            raise HTTPException(\n",
      "                status_code=400,\n",
      "                detail=\"El tamaÃ±o del lote debe estar entre 1 y 1000 registros\"\n",
      "            )\n",
      "        \n",
      "        # Insertar los datos en la base de datos\n",
      "        db_manager = DatabaseManager()\n",
      "        inserted_count = db_manager.insert_batch(table_name, data)\n",
      "        \n",
      "        return JSONResponse(\n",
      "            status_code=201,\n",
      "            content={\n",
      "                \"message\": f\"Archivo CSV cargado exitosamente en la tabla {table_name}\",\n",
      "                \"records_inserted\": inserted_count\n",
      "            }\n",
      "        )\n",
      "    \n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=500, detail=str(e))\n",
      "    \n",
      "    finally:\n",
      "        # Eliminar el archivo temporal\n",
      "        if os.path.exists(temp_file.name):\n",
      "            os.unlink(temp_file.name)\n",
      "\n",
      "# Endpoint para insertar un lote de registros\n",
      "@app.post(\"/batch/{table_name}\")\n",
      "async def insert_batch(table_name: str, data: List[Dict[str, Any]] = Body(...)):\n",
      "    \"\"\"\n",
      "    Inserta un lote de registros en la tabla especificada.\n",
      "    \n",
      "    Args:\n",
      "        table_name: Nombre de la tabla donde insertar los datos (departments, jobs, hired_employees).\n",
      "        data: Lista de diccionarios con los datos a insertar.\n",
      "        \n",
      "    Returns:\n",
      "        Mensaje de Ã©xito y nÃºmero de registros insertados.\n",
      "    \"\"\"\n",
      "    # Validar el nombre de la tabla\n",
      "    valid_tables = [\"departments\", \"jobs\", \"hired_employees\"]\n",
      "    if table_name not in valid_tables:\n",
      "        raise HTTPException(\n",
      "            status_code=400, \n",
      "            detail=f\"Tabla no vÃ¡lida. Debe ser una de: {', '.join(valid_tables)}\"\n",
      "        )\n",
      "    \n",
      "    # Validar el tamaÃ±o del lote\n",
      "    if not validate_batch_size(data):\n",
      "        raise HTTPException(\n",
      "            status_code=400,\n",
      "            detail=\"El tamaÃ±o del lote debe estar entre 1 y 1000 registros\"\n",
      "        )\n",
      "    \n",
      "    try:\n",
      "        # Insertar los datos en la base de datos\n",
      "        db_manager = DatabaseManager()\n",
      "        inserted_count = db_manager.insert_batch(table_name, data)\n",
      "        \n",
      "        return JSONResponse(\n",
      "            status_code=201,\n",
      "            content={\n",
      "                \"message\": f\"Lote insertado exitosamente en la tabla {table_name}\",\n",
      "                \"records_inserted\": inserted_count\n",
      "            }\n",
      "        )\n",
      "    \n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=500, detail=str(e))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ver el contenido del script main.py\n",
    "with open('app/main.py', 'r') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 7: Iniciar la API REST\n",
    "\n",
    "Para iniciar la API REST, necesitamos ejecutar el siguiente comando en una terminal:\n",
    "\n",
    "```bash\n",
    "uvicorn app.main:app --host 127.0.0.1 --port 8080\n",
    "```\n",
    "\n",
    "Esto iniciará el servidor en http://localhost:8080.\n",
    "\n",
    "**Nota**: No podemos ejecutar este comando directamente en el notebook porque bloquearía la ejecución de las siguientes celdas. En su lugar, puedes abrir una terminal separada y ejecutar el comando allí."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 8: Pruebas de la API\n",
    "\n",
    "Veamos el script de pruebas de la API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "Script para probar la API REST\n",
      "\"\"\"\n",
      "import os\n",
      "import requests\n",
      "import json\n",
      "\n",
      "# ConfiguraciÃ³n\n",
      "API_URL = \"http://localhost:8080\"\n",
      "DATA_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"data\")\n",
      "\n",
      "def test_api_status():\n",
      "    \"\"\"Prueba el estado de la API\"\"\"\n",
      "    print(\"\\n=== Probando estado de la API ===\")\n",
      "    response = requests.get(f\"{API_URL}/\")\n",
      "    print(f\"Respuesta: {response.status_code}\")\n",
      "    print(json.dumps(response.json(), indent=2))\n",
      "    return response.status_code == 200\n",
      "\n",
      "def test_upload_csv(table_name, file_path):\n",
      "    \"\"\"Prueba la carga de un archivo CSV\"\"\"\n",
      "    print(f\"\\n=== Probando carga de CSV para {table_name} ===\")\n",
      "    with open(file_path, 'rb') as file:\n",
      "        files = {'file': (os.path.basename(file_path), file, 'text/csv')}\n",
      "        response = requests.post(f\"{API_URL}/upload/{table_name}\", files=files)\n",
      "    \n",
      "    print(f\"Respuesta: {response.status_code}\")\n",
      "    print(json.dumps(response.json(), indent=2))\n",
      "    return response.status_code == 201\n",
      "\n",
      "def test_batch_insert(table_name, data):\n",
      "    \"\"\"Prueba la inserciÃ³n por lotes\"\"\"\n",
      "    print(f\"\\n=== Probando inserciÃ³n por lotes para {table_name} ===\")\n",
      "    response = requests.post(\n",
      "        f\"{API_URL}/batch/{table_name}\",\n",
      "        json=data,\n",
      "        headers={\"Content-Type\": \"application/json\"}\n",
      "    )\n",
      "    \n",
      "    print(f\"Respuesta: {response.status_code}\")\n",
      "    print(json.dumps(response.json(), indent=2))\n",
      "    return response.status_code == 201\n",
      "\n",
      "def main():\n",
      "    \"\"\"FunciÃ³n principal para ejecutar todas las pruebas\"\"\"\n",
      "    print(\"Iniciando pruebas de la API REST...\")\n",
      "    \n",
      "    # Probar estado de la API\n",
      "    if not test_api_status():\n",
      "        print(\"Error: La API no estÃ¡ disponible. AsegÃºrate de que estÃ© en ejecuciÃ³n.\")\n",
      "        return\n",
      "    \n",
      "    # Probar carga de CSV\n",
      "    departments_csv = os.path.join(DATA_DIR, \"departments.csv\")\n",
      "    jobs_csv = os.path.join(DATA_DIR, \"jobs.csv\")\n",
      "    employees_csv = os.path.join(DATA_DIR, \"hired_employees.csv\")\n",
      "    \n",
      "    test_upload_csv(\"departments\", departments_csv)\n",
      "    test_upload_csv(\"jobs\", jobs_csv)\n",
      "    test_upload_csv(\"hired_employees\", employees_csv)\n",
      "    \n",
      "    # Probar inserciÃ³n por lotes\n",
      "    departments_batch = [\n",
      "        {\"id\": 12, \"department\": \"Quality Assurance\"},\n",
      "        {\"id\": 13, \"department\": \"Customer Support\"}\n",
      "    ]\n",
      "    \n",
      "    jobs_batch = [\n",
      "        {\"id\": 183, \"job\": \"Data Scientist\"},\n",
      "        {\"id\": 184, \"job\": \"DevOps Engineer\"}\n",
      "    ]\n",
      "    \n",
      "    employees_batch = [\n",
      "        {\n",
      "            \"id\": 2000,\n",
      "            \"name\": \"John Doe\",\n",
      "            \"datetime\": \"2022-01-01T10:00:00Z\",\n",
      "            \"department_id\": 5,\n",
      "            \"job_id\": 10\n",
      "        },\n",
      "        {\n",
      "            \"id\": 2001,\n",
      "            \"name\": \"Jane Smith\",\n",
      "            \"datetime\": \"2022-01-02T11:30:00Z\",\n",
      "            \"department_id\": 3,\n",
      "            \"job_id\": 15\n",
      "        }\n",
      "    ]\n",
      "    \n",
      "    test_batch_insert(\"departments\", departments_batch)\n",
      "    test_batch_insert(\"jobs\", jobs_batch)\n",
      "    test_batch_insert(\"hired_employees\", employees_batch)\n",
      "    \n",
      "    print(\"\\n=== Pruebas completadas ===\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ver el contenido del script test_api.py\n",
    "with open('test_api.py', 'r') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ejecutar las pruebas, necesitas tener la API en ejecución en otra terminal. Luego, puedes ejecutar el siguiente comando:\n",
    "\n",
    "```bash\n",
    "python test_api.py\n",
    "```\n",
    "\n",
    "O puedes ejecutar las pruebas manualmente, como se muestra a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta: 200\n",
      "{\n",
      "  \"message\": \"API de Migraci\\u00f3n CSV activa\",\n",
      "  \"status\": \"OK\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Prueba manual del estado de la API (asegúrate de que la API esté en ejecución)\n",
    "import requests\n",
    "import json\n",
    "\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:8080/\")\n",
    "    print(f\"Respuesta: {response.status_code}\")\n",
    "    print(json.dumps(response.json(), indent=2))\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Error: No se pudo conectar a la API. Asegúrate de que esté en ejecución.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 9: Prueba de Carga de CSV\n",
    "\n",
    "Si la API está en ejecución, podemos probar la carga de un archivo CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta: 500\n",
      "{\n",
      "  \"detail\": \"UNIQUE constraint failed: departments.id\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Prueba de carga de CSV (asegúrate de que la API esté en ejecución)\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    # Cargar el archivo departments.csv\n",
    "    departments_csv = os.path.join(data_dir, 'departments.csv')\n",
    "    \n",
    "    with open(departments_csv, 'rb') as file:\n",
    "        files = {'file': (os.path.basename(departments_csv), file, 'text/csv')}\n",
    "        response = requests.post(\"http://localhost:8080/upload-from-path/departments\", \n",
    "                                 json={\"file_path\": departments_csv},\n",
    "                                 headers={\"Content-Type\": \"application/json\"}\n",
    "                                )\n",
    "    \n",
    "    print(f\"Respuesta: {response.status_code}\")\n",
    "    print(json.dumps(response.json(), indent=2))\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Error: No se pudo conectar a la API. Asegúrate de que esté en ejecución.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 10: Prueba de Inserción por Lotes\n",
    "\n",
    "Si la API está en ejecución, podemos probar la inserción de un lote de registros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta: 201\n",
      "{\n",
      "  \"message\": \"Lote insertado exitosamente en la tabla departments\",\n",
      "  \"records_inserted\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Prueba de inserción por lotes (asegúrate de que la API esté en ejecución)\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    # Datos de prueba\n",
    "    departments_batch = [\n",
    "        {\"id\": 101, \"department\": \"Quality Assurance\"},\n",
    "        {\"id\": 102, \"department\": \"Customer Support\"}\n",
    "    ]\n",
    "    \n",
    "    response = requests.post(\n",
    "        \"http://localhost:8080/batch/departments\",\n",
    "        json=departments_batch,\n",
    "        headers={\"Content-Type\": \"application/json\"}\n",
    "    )\n",
    "    \n",
    "    print(f\"Respuesta: {response.status_code}\")\n",
    "    print(json.dumps(response.json(), indent=2))\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Error: No se pudo conectar a la API. Asegúrate de que esté en ejecución.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 11: Verificación de Datos en la Base de Datos\n",
    "\n",
    "Podemos verificar que los datos se hayan insertado correctamente en la base de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de departamentos: 5\n",
      "Primeros 10 departamentos:\n",
      "  1. ID: 12, Nombre: Quality Assurance\n",
      "  2. ID: 13, Nombre: Customer Support\n",
      "  3. ID: 100, Nombre: Test Department\n",
      "  4. ID: 101, Nombre: Quality Assurance\n",
      "  5. ID: 102, Nombre: Customer Support\n",
      "\n",
      "Número de trabajos: 2\n",
      "Primeros 10 trabajos:\n",
      "  1. ID: 183, Nombre: Data Scientist\n",
      "  2. ID: 184, Nombre: DevOps Engineer\n",
      "\n",
      "Número de empleados: 2\n",
      "Primeros 10 empleados:\n",
      "  1. ID: 2000, Nombre: John Doe, Fecha: 2022-01-01T10:00:00Z, Depto: 5, Trabajo: 10\n",
      "  2. ID: 2001, Nombre: Jane Smith, Fecha: 2022-01-02T11:30:00Z, Depto: 3, Trabajo: 15\n"
     ]
    }
   ],
   "source": [
    "# Verificar los datos en la base de datos\n",
    "from app.database.db_manager import DatabaseManager\n",
    "\n",
    "# Crear una instancia del gestor de base de datos\n",
    "db_manager = DatabaseManager()\n",
    "\n",
    "# Consultar los departamentos\n",
    "departments = db_manager.execute_query(\"SELECT * FROM departments\")\n",
    "print(f\"Número de departamentos: {len(departments)}\")\n",
    "print(\"Primeros 10 departamentos:\")\n",
    "for i, dept in enumerate(departments[:10]):\n",
    "    print(f\"  {i+1}. ID: {dept[0]}, Nombre: {dept[1]}\")\n",
    "\n",
    "# Consultar los trabajos\n",
    "jobs = db_manager.execute_query(\"SELECT * FROM jobs\")\n",
    "print(f\"\\nNúmero de trabajos: {len(jobs)}\")\n",
    "print(\"Primeros 10 trabajos:\")\n",
    "for i, job in enumerate(jobs[:10]):\n",
    "    print(f\"  {i+1}. ID: {job[0]}, Nombre: {job[1]}\")\n",
    "\n",
    "# Consultar los empleados\n",
    "employees = db_manager.execute_query(\"SELECT * FROM hired_employees\")\n",
    "print(f\"\\nNúmero de empleados: {len(employees)}\")\n",
    "print(\"Primeros 10 empleados:\")\n",
    "for i, emp in enumerate(employees[:10]):\n",
    "    print(f\"  {i+1}. ID: {emp[0]}, Nombre: {emp[1]}, Fecha: {emp[2]}, Depto: {emp[3]}, Trabajo: {emp[4]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen\n",
    "\n",
    "En este notebook, hemos explorado y ejecutado paso a paso cada componente del proyecto de API REST para migración de datos CSV a una base de datos SQL:\n",
    "\n",
    "1. Analizamos la estructura de los archivos CSV\n",
    "2. Creamos la base de datos SQLite\n",
    "3. Probamos el gestor de base de datos\n",
    "4. Probamos el procesador de archivos CSV\n",
    "5. Examinamos la API REST principal\n",
    "6. Probamos la API (si estaba en ejecución)\n",
    "7. Verificamos los datos en la base de datos\n",
    "\n",
    "Para ejecutar la API completa, recuerda que debes ejecutar el siguiente comando en una terminal:\n",
    "\n",
    "```bash\n",
    "uvicorn app.main:app --reload\n",
    "```\n",
    "\n",
    "Y para probar la API, puedes ejecutar:\n",
    "\n",
    "```bash\n",
    "python test_api.py\n",
    "```\n",
    "\n",
    "O acceder a la documentación interactiva en:\n",
    "- Swagger UI: http://localhost:8000/docs\n",
    "- ReDoc: http://localhost:8000/redoc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
